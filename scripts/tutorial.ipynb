{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a package I have created, as well as other packages, we have to import them. If you haven't used a jupyter notebook before then you can press control enter to run the code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  # Allows you to set levels of verbosity for printing information warnings and errors\n",
    "import elfi  # SMC / Liklihood free inference\n",
    "import numpy as np  # Matrices and linear algebra\n",
    "import scipy.stats  # Statistics\n",
    "import seaborn as sns  # Plotting\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "from sklearn.preprocessing import StandardScaler  # Carries out standard scaling (x-mu)/sd\n",
    "import pandas as pd  # DataFrames\n",
    "import pickle  # Serializes objects\n",
    "\n",
    "# The sim package is my package (in the sim folder)\n",
    "from sim.utils import ScaledDist\n",
    "from sim.model import elfi_sim\n",
    "from sim.sum_stats import elfi_sum\n",
    "\n",
    "# Set the logging level to info\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run a simulation, the simplest way (which is elfi compatible) is shown below. Note that the square brackets mean that those parameters are lists. The length of these lists should match the `batch_size` parameter, but `batch_size=1` should be fine in general, it just needs to exist to keep elfi happy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Param bottleneck_strength_domestic = [3000]\n",
      "INFO:root:Param bottleneck_strength_wild = [30000]\n",
      "INFO:root:Param bottleneck_time_domestic = [3000]\n",
      "INFO:root:Param bottleneck_time_wild = [4000]\n",
      "INFO:root:Param captive_time = [20]\n",
      "INFO:root:Param div_time = [40000]\n",
      "INFO:root:Param mig_length_post_split = [1000]\n",
      "INFO:root:Param mig_length_wild = [20]\n",
      "INFO:root:Param mig_rate_captive = [0.01]\n",
      "INFO:root:Param mig_rate_post_split = [0.1]\n",
      "INFO:root:Param mig_rate_wild = [0.01]\n",
      "INFO:root:Param pop_size_captive = [1000]\n",
      "INFO:root:Param pop_size_domestic_1 = [100]\n",
      "INFO:root:Param pop_size_domestic_2 = [100]\n",
      "INFO:root:Param pop_size_wild_1 = [500]\n",
      "INFO:root:Param pop_size_wild_2 = [500]\n",
      "INFO:root:Running command: slim -d captive_time=20 -d mig_length_wild=20 -d mig_rate_captive=0.01 -d mig_rate_wild=0.01 -d pop_size_captive=1000 -d pop_size_domestic_1=100 -d pop_size_wild_1=500 -d length=10000000 -d recombination_rate=1.8e-08  -d decap_trees_filename='\"../output/decap_218175339.trees\"' -s 40 slim_model.slim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "pod has shape (1, 1)\n",
      "CPU times: user 1.09 s, sys: 62.3 ms, total: 1.15 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pod = elfi_sim(\n",
    "        bottleneck_strength_domestic=[3000],\n",
    "        bottleneck_strength_wild=[30000],\n",
    "        bottleneck_time_domestic=[3000],\n",
    "        bottleneck_time_wild=[4000],\n",
    "        captive_time=[20],\n",
    "        div_time=[40000],\n",
    "        mig_length_post_split=[1000],\n",
    "        mig_length_wild=[20],\n",
    "        mig_rate_captive=[0.01],\n",
    "        mig_rate_post_split=[0.1],\n",
    "        mig_rate_wild=[0.01],\n",
    "        pop_size_captive=[1000],\n",
    "        pop_size_domestic_1=[100],\n",
    "        pop_size_domestic_2=[100],\n",
    "        pop_size_wild_1=[500],\n",
    "        pop_size_wild_2=[500],\n",
    "        length=int(10e6),\n",
    "        recombination_rate=1.8e-8,\n",
    "        mutation_rate=6e-8,\n",
    "        random_state=np.random.RandomState(3),\n",
    "        batch_size=1\n",
    ") \n",
    "\n",
    "print(f\"pod has shape {pod.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation results format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a 1 by 1 numpy matrix. axis 0 corresponds to the batch_size (rows), axis 1 corresponds to simulation outputs (which in our use case is always of shape 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod = pod[0, 0]  # Get the result out the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pod` is an instance of a `GenotypeData` class, which I have defined in model.py. The attributes of the class have things you need for summary statistic calculation. For example, `pod.genotypes[\"domestic\"]` would give you an array of the domestic genotypes. `pod.positions` gives a 1d array of the mutation positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53079, 5, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pod.genotypes[\"domestic\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53079, 30, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pod.genotypes[\"wild\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the positions of the mutations with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.48133458e+02, 5.36448486e+02, 1.02672364e+03, ...,\n",
       "       9.99987753e+06, 9.99993280e+06, 9.99995413e+06])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pod.positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genotypes are given as 3 dimensional, where axis 0 is variants, axis 1 is individuals and axis 2 is ploidy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the summary statistics can be calculated with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 102)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats = elfi_sum(pod)\n",
    "summary_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this is two dimensional, in which axis 0 is of size batch_size, and axis 1 is the number of summary statistics. You can have a look through sum_stats.py if you want to calculate specific summary statistics, for example to do a PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sim.sum_stats import pca\n",
    "pod.allelify()  # convert from numpy to scikit allel equivilents\n",
    "pca_data = pca(pod.genotypes[\"all_pops\"].to_n_alt(), pod.subpops)  # to_n_alt converts to 012 format\n",
    "sns.scatterplot(pca_data[\"pc1\"], pca_data[\"pc2\"], hue=pca_data[\"population\"])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to add more summary statistics, I would suggest adding it as a function in sum_stats.py, which is then called in the `elfi_summary` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using elfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In elfi, SMC (and bolfi too if you use that), kicks up a fuss if parameters are badly scaled. To overcome this priors are defined using a class ScaledDist (from sim.utils.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sim.utils import ScaledDist\n",
    "fake_prior = ScaledDist(sampling=scipy.stats.lognorm(s=0.4, loc=0, scale=1),  # elfi will sample and infer from this distribution\n",
    "                        target=scipy.stats.lognorm(s=0.4, loc=1, scale=np.exp(2.7)))  # elfi will scale up to this distribution in the simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first distribution doesn't really matter, apart from it should be a standardish scale, and it's shape should match the target distribution so it can be scaled up. The second distribution is our actual prior. This means that the only thing that should change in between the distributions are the `loc` and `scale` parameters. To ensure that scaling works as expected, you can plot the target distribution against a scaled set of samples from the sampling distribution, and check the distributions match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_prior.plot(show_scaled_kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have already run priors.py you should be able to load the priors with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../output/priors.pkl\", \"rb\") as f:\n",
    "    priors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors[\"div_time\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way I got the real data into the same format as the results from the simulations (i.e. an instance of the `GenotypeData` class) is shown below. I thought that although I have done it for the phased data you have given me, in case you want to do it for a different chromosome, or using phasing by a different method, then it may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "from sim.model import GenotypeData\n",
    "callset = allel.read_vcf(\"../data/e3_phased.vcf\")  #  This is the vcf file you have given me\n",
    "pop = pd.read_csv(\"../data/e3_sample_info.csv\", usecols=[\"SOURCE\"])[\"SOURCE\"].str.lower().to_numpy().ravel()\n",
    "\n",
    "subpops = {}\n",
    "for pop_name in np.unique(pop):\n",
    "    subpops[pop_name] = np.where(pop == pop_name)[0]\n",
    "\n",
    "subpops[\"all_pops\"] = np.arange(len(pop))\n",
    "\n",
    "y_obs = GenotypeData(callset=callset, subpops=subpops, seq_length=44648284)\n",
    "\n",
    "with open(\"../data/e3_phased.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_obs, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this will automatically converts the data to biallelic matrices. It also saves the object created using pickle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
