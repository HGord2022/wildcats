{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Script plots a PCA for the observed data, alongside a PCA using simulated data, utilising the medians of the priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "All imports occur here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sim.model import SeqFeatures, WildcatSimulation\n",
    "from sim import sum_stats as ss\n",
    "import time\n",
    "import tskit\n",
    "import msprime\n",
    "import allel\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose parameters\n",
    "Choose some parameters so it runs relatively quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features = SeqFeatures(length=int(20e6), recombination_rate=1.8e-8, mutation_rate=6e-8)\n",
    "\n",
    "slim_parameters = {\n",
    "    'pop_size_domestic_1': 2000,  # Population sizes are diploid.\n",
    "    'pop_size_wild_1': 2000,\n",
    "    'pop_size_captive': 70,\n",
    "    'mig_rate_captive': 0.005,  # Migration from wild -> captive\n",
    "    'mig_length_wild': 34,\n",
    "    'mig_rate_wild': 0.008,  # Rate of migration from domestic -> wildcats\n",
    "    'captive_time': 28,  # Time captive population established in SLiM\n",
    "    }\n",
    "\n",
    "recapitate_parameters = {\n",
    "        'pop_size_domestic_2': 4000,\n",
    "        'pop_size_wild_2': 4000,\n",
    "        'div_time': 40000,\n",
    "        'mig_rate_post_split': 0.005,\n",
    "        'mig_length_post_split': 5000,\n",
    "        'bottleneck_time_wild': 3000,\n",
    "        'bottleneck_strength_wild': 20000,\n",
    "        'bottleneck_time_domestic': 3000,\n",
    "        'bottleneck_strength_domestic': 20000,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 8.18 s\n",
      "Command ran: slim -d pop_size_domestic_1=2000 -d pop_size_wild_1=2000 -d pop_size_captive=70 -d mig_rate_captive=0.005 -d mig_length_wild=34 -d mig_rate_wild=0.008 -d captive_time=28 -d length=20000000 -d recombination_rate=1.8e-08  -d decap_trees_filename='\"../output/decap_40.trees\"' -s 40 slim_model.slim\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Run model\n",
    "sim = WildcatSimulation(seq_features=seq_features, random_seed=40)\n",
    "command = sim.slim_command(slim_parameters)\n",
    "decap_trees = sim.run_slim(command)\n",
    "demographic_events = sim.demographic_model(**recapitate_parameters)\n",
    "tree_seq = sim.recapitate(decap_trees, demographic_events)\n",
    "\n",
    "# Print out useful bits and bobs\n",
    "print(\"Simulation finished in {:.2f} s\".format(time.time()-start_time))\n",
    "print(\"Command ran: {}\".format(command))\n",
    "# tree_seq.slim_provenance.model_type = \"WF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [5, 30, 10])  # Match number of samples to the WGS data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "genotypes = ss.genotypes(tree_seq)\n",
    "pos = ss.positions(tree_seq)\n",
    "pop_list = ss.pop_list(tree_seq)\n",
    "samples = ss.sampled_nodes(tree_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tsinfer ancestral state irrelevant toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-8e77b64184ce>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-8e77b64184ce>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pyslim.make_slim_provenance_dict(\"real_data\",` 500)\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pyslim.make_slim_provenance_dict(\"real_data\",` 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(np.array(genotypes), \"../output/test_genotypes.joblib\")\n",
    "joblib.dump(pos, \"../output/test_pos.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"AB\": [1,2,3], \"AC\": [5,4,5], \"CC\": [5,7,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in list(df) if \"A\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.loadtxt(\"../data/e3.012.pos\", delimiter=\"\\t\", usecols=1)\n",
    "genotypes = np.loadtxt(\"../data/e3.012\", delimiter=\"\\t\", usecols=range(1, len(positions)+1))\n",
    "genotypes = genotypes.T\n",
    "assert len(positions) == genotypes.shape[0]\n",
    "\n",
    "# For now just assume that missings are ancestral\n",
    "genotypes[genotypes == -1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cam read in with scikit allel but genotypes looks dodge\n",
    "callset = allel.read_vcf(\"../data/e3.vcf\")\n",
    "pos = callset[\"variants/POS\"]\n",
    "genotypes = allel.GenotypeArray(callset[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset[\"samples\"][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline(genotypes, pos, pop_list):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes, pop_list)\n",
    "    return pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = pd.read_csv(\"../data/e3_sample_info.csv\", usecols=[\"NAME\", \"SOURCE\"])\n",
    "\n",
    "# Ensure that individuals are in same order (after 012 conversion)\n",
    "assert np.all(sample_info[\"NAME\"] == np.loadtxt(\"../data/e3.012.indv\", dtype=str))\n",
    "\n",
    "pca_pipeline(genotypes, pos, sample_info[\"SOURCE\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsinfer\n",
    "\n",
    "with tsinfer.SampleData(sequence_length=6) as sample_data:\n",
    "    sample_data.add_site(0, [0, 1, 0, 0, 0], [\"A\", \"T\"])\n",
    "    sample_data.add_site(1, [0, 0, 0, 1, 1], [\"G\", \"C\"])\n",
    "    sample_data.add_site(2, [0, 1, 1, 0, 0], [\"C\", \"A\"])\n",
    "    sample_data.add_site(3, [0, 1, 1, 0, 0], [\"G\", \"C\"])\n",
    "    sample_data.add_site(4, [0, 0, 0, 1, 1], [\"A\", \"C\"])\n",
    "    sample_data.add_site(5, [0, 1, 2, 0, 0], [\"T\", \"G\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline(genotypes, pos, pop_list):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes, pop_list)\n",
    "    return pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_functions = [\n",
    "    ss.tskit_stats(tree_seq, samples),\n",
    "    ss.afs_stats(tree_seq, samples),\n",
    "    ss.r2_stats(tree_seq, samples, [0, 1e6, 2e6, 4e6], labels=[\"0_1Mb\", \"1_2Mb\", \"2_4MB\"]),\n",
    "    ss.roh_stats(genotypes, pos, pop_list, seq_features.length),\n",
    "    pca_pipeline(genotypes, pos, pop_list),\n",
    "]\n",
    "\n",
    "stats_dict = {\"random_seed\": sim.random_seed}  # Random seed acts as ID\n",
    "\n",
    "for func in summary_functions:\n",
    "    stat = func\n",
    "    stats_dict = {**stats_dict, **stat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_seed': 40,\n",
       " 'domestic_diversity': 0.0002498288888888511,\n",
       " 'wild_diversity': 0.0024719459604512217,\n",
       " 'captive_diversity': 0.0009857676315784575,\n",
       " 'domestic_segregating_sites': 0.0007919,\n",
       " 'wild_segregating_sites': 0.0081945,\n",
       " 'captive_segregating_sites': 0.0038628,\n",
       " 'domestic_tajimas_d': -0.5401953037193947,\n",
       " 'wild_tajimas_d': 1.4615745961680253,\n",
       " 'captive_tajimas_d': -0.39725974099795774,\n",
       " 'dom_wild_f2': 0.0033114010753336385,\n",
       " 'dom_cap_f2': 0.005073923239768081,\n",
       " 'wild_cap_f2': 0.0002057429539844997,\n",
       " 'dom_wild_divergence': 0.0046722884999969546,\n",
       " 'dom_cap_divergence': 0.005691721500004096,\n",
       " 'wild_cap_divergence': 0.001934599750000651,\n",
       " 'domestic_f3': 0.004089790680553033,\n",
       " 'wild_f3': -0.0007783896052255832,\n",
       " 'captive_f3': 0.000984132559210339,\n",
       " 'domestic_y3': 0.00421470512499767,\n",
       " 'wild_y3': 0.0004575833750000667,\n",
       " 'captive_y3': 0.0014770163749996965,\n",
       " 'dom_wild_fst': 0.5488653267656363,\n",
       " 'dom_cap_fst': 0.8041694823980153,\n",
       " 'wild_cap_fst': 0.05616088287155607,\n",
       " 'all_pops_diversity': 0.002705897528085519,\n",
       " 'all_pops_segregating_sites': 0.00852705,\n",
       " 'all_pops_tajimas_d': 2.1032709244053627,\n",
       " 'domestic_afs_mean_1_2': 5804.5,\n",
       " 'domestic_afs_mean_3_3': 2091.0,\n",
       " 'domestic_afs_mean_4_4': 1461.0,\n",
       " 'domestic_afs_mean_5_5': 677.0,\n",
       " 'wild_afs_mean_1_8': 5249.0,\n",
       " 'wild_afs_mean_9_16': 10483.75,\n",
       " 'wild_afs_mean_17_23': 5322.571428571428,\n",
       " 'wild_afs_mean_24_30': 110.0,\n",
       " 'captive_afs_mean_1_3': 17342.666666666668,\n",
       " 'captive_afs_mean_4_6': 7534.666666666667,\n",
       " 'captive_afs_mean_7_8': 811.5,\n",
       " 'captive_afs_mean_9_10': 500.5,\n",
       " 'all_pops_afs_mean_1_12': 3982.5,\n",
       " 'all_pops_afs_mean_13_23': 2917.818181818182,\n",
       " 'all_pops_afs_mean_24_34': 8171.545454545455,\n",
       " 'all_pops_afs_mean_35_45': 69.81818181818181,\n",
       " 'all_pops_r2_median_0_1Mb': 0.6417506313624411,\n",
       " 'all_pops_r2_median_1_2Mb': 0.4018777926509682,\n",
       " 'all_pops_r2_median_2_4MB': 0.2431500025709584,\n",
       " 'captive_r2_median_0_1Mb': 1.0,\n",
       " 'captive_r2_median_1_2Mb': 0.47368421052631593,\n",
       " 'captive_r2_median_2_4MB': 0.04411764705882355,\n",
       " 'domestic_r2_median_0_1Mb': 0.04761904761904761,\n",
       " 'domestic_r2_median_1_2Mb': 0.04761904761904761,\n",
       " 'domestic_r2_median_2_4MB': 0.04761904761904761,\n",
       " 'wild_r2_median_0_1Mb': 0.44362025464596355,\n",
       " 'wild_r2_median_1_2Mb': 0.2038396386222473,\n",
       " 'wild_r2_median_2_4MB': 0.09482758620689656,\n",
       " 'all_pops_r2_iqr_0_1Mb': 0.8320539519566058,\n",
       " 'all_pops_r2_iqr_1_2Mb': 0.574066584753889,\n",
       " 'all_pops_r2_iqr_2_4MB': 0.38242484981788927,\n",
       " 'captive_r2_iqr_0_1Mb': 0.7352941176470588,\n",
       " 'captive_r2_iqr_1_2Mb': 0.9722222222222222,\n",
       " 'captive_r2_iqr_2_4MB': 0.2850877192982456,\n",
       " 'domestic_r2_iqr_0_1Mb': 0.12827932098765432,\n",
       " 'domestic_r2_iqr_1_2Mb': 0.09876543209876545,\n",
       " 'domestic_r2_iqr_2_4MB': 0.09876543209876543,\n",
       " 'wild_r2_iqr_0_1Mb': 0.7344080714666634,\n",
       " 'wild_r2_iqr_1_2Mb': 0.4170484731360246,\n",
       " 'wild_r2_iqr_2_4MB': 0.21549054739767934,\n",
       " 'captive_roh_length_median': 3079999.0,\n",
       " 'domestic_roh_length_median': 2290499.0,\n",
       " 'wild_roh_length_median': 1686999.0,\n",
       " 'all_pops_roh_length_median': 1926999.0,\n",
       " 'captive_roh_length_iqr': 6682000.0,\n",
       " 'domestic_roh_length_iqr': 3903250.0,\n",
       " 'wild_roh_length_iqr': 2504000.0,\n",
       " 'all_pops_roh_length_iqr': 3355000.0,\n",
       " 'domestic_roh_cov_median': 0.9987497,\n",
       " 'domestic_roh_cov_iqr': 0.0017001999999999295,\n",
       " 'wild_roh_cov_median': 0.686599725,\n",
       " 'wild_roh_cov_iqr': 0.3113874124999999,\n",
       " 'captive_roh_cov_median': 0.84402475,\n",
       " 'captive_roh_cov_iqr': 0.16412503750000007,\n",
       " 'all_pops_roh_cov_median': 0.76714985,\n",
       " 'all_pops_roh_cov_iqr': 0.34305030000000003,\n",
       " 'captive_pc1_iqr': 12.044548034667969,\n",
       " 'captive_pc2_iqr': 11.438492774963379,\n",
       " 'domestic_pc1_iqr': 1.686920166015625,\n",
       " 'domestic_pc2_iqr': 1.5721073150634766,\n",
       " 'wild_pc1_iqr': 36.921627044677734,\n",
       " 'wild_pc2_iqr': 20.65810775756836,\n",
       " 'all_pops_pc1_iqr': 53.29386901855469,\n",
       " 'all_pops_pc2_iqr': 48.26140022277832,\n",
       " 'pc1_pairwise_medians_dom_wild': 131.79478454589844,\n",
       " 'pc2_pairwise_medians_dom_wild': 39.563331604003906,\n",
       " 'pc1_pairwise_medians_dom_cap': 172.15538024902344,\n",
       " 'pc2_pairwise_medians_dom_cap': 33.020286560058594,\n",
       " 'pc1_pairwise_medians_wild_cap': 40.360595703125,\n",
       " 'pc2_pairwise_medians_wild_cap': 72.5836181640625}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caluculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f9a9ee6e096c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m46\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Match number of samples to the WGS data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtree_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Calculate summary statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpca_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenotypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\wildcats_summer\\scripts\\sim\\model.py\u001b[0m in \u001b[0;36msample_nodes\u001b[1;34m(self, tree_seq, sample_sizes)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpop_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamp_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mpop_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mind_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"population\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpop_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0mpop_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamp_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m             \u001b[0mpop_sample_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"node_0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpop_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"node_1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0msample_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_sample_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\wildcats_summer_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[0;32m   5059\u001b[0m             )\n\u001b[0;32m   5060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5061\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5062\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the WGS data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "\n",
    "# Calculate summary statistics\n",
    "def pca_pipeline(genotypes, pos):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes)\n",
    "    return pca_stats\n",
    "\n",
    "genotypes = ss.genotypes(tree_seq)  # scikit-allel format\n",
    "pos = ss.positions(tree_seq)\n",
    "\n",
    "# Using a list to call function in for loop so we can use try/except (in case any functions fail)\n",
    "summary_functions = [\n",
    "    sum_stats.tskit_stats(),\n",
    "    sum_stats.afs_stats(),\n",
    "    sum_stats.r2_stats(),\n",
    "    sum_stats.roh_stats(genotypes, pos),\n",
    "    pca_pipeline(genotypes, pos),\n",
    "]\n",
    "\n",
    "stats_dict = {\"random_seed\": sim.random_seed}  # Random seed acts as ID\n",
    "\n",
    "for func in summary_functions:\n",
    "    stat = func\n",
    "    stats_dict = {**stats_dict, **stat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_stats = {'domestic_roh_cov_median': 0.9996666, 'domestic_roh_cov_iqr': 0.00022224444444440827, 'wild_roh_cov_median': 0.6211887222222223, 'wild_roh_cov_iqr': 0.19288330555555555, 'captive_roh_cov_median': 0.8555888222222222, 'captive_roh_cov_iqr': 0.10507222222222223}\n",
    "coverage_stats[\"all_pops_roh_cov_median\"] = np.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(prior_df[[\"mig_rate_wild\", \"mig_rate_post_split\"]]<=1) & np.all(prior_df[[\"mig_rate_wild\", \"mig_rate_post_split\"]]>=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ROH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below seems fine but we should probably filter minor alleles. With this a single mutation breaks a ROH... I think that is ok? Presumably v. informative for PODs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the SNP data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "sum_stats = SummaryStatistics(tree_seq, sim)\n",
    "genotypes = sum_stats.sampled_genotypes()\n",
    "is_homo = genotypes[:,:,0] == genotypes[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roh_id = pd.DataFrame(np.cumsum(is_homo == False, axis=0))  # Increment ID with each heterozygote\n",
    "roh_id[\"position\"] = sim_tools.positions(tree_seq)\n",
    "df = roh_id.melt(id_vars=\"position\", var_name=\"individual\", value_name=\"roh_id\")\n",
    "df = df.groupby([\"individual\", \"roh_id\"])[\"position\"].max().reset_index()\n",
    "df[\"roh_length\"] = df.groupby('individual')['position'].diff(1)\n",
    "df = df.dropna()  # Drops first \"ROH\" (as no previous heterozygote)\n",
    "df = df.drop(columns = [\"position\", \"roh_id\"])\n",
    "# pd.DataFrame({\"population\": sum_stats.individual_pop_list, \"id\": range(0, len(sum_stats.individual_pop_list))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a sample and get the genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the SNP data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes = ss.genotypes(tree_seq)\n",
    "pos = ss.positions(tree_seq)\n",
    "pop_list = ss.pop_list(tree_seq)\n",
    "samples = ss.sampled_nodes(tree_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ld(gn, title):\n",
    "    m = allel.rogers_huff_r(gn) ** 2\n",
    "    ax = allel.plot_pairwise_ld(m)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ld(genotypes[:1000].to_n_alt(), 'Pairwise LD.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter singletons and SNPs in LD\n",
    "SNPs in LD can bias PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "genotypes, pos = ss.ld_prune(genotypes.to_n_alt(), pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ld(genotypes[:1000], 'Pairwise LD after pruning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_population = np.asarray([\"domestic\"]*4 + [\"wild\"]*45 + [\"captive\"]*46)\n",
    "populations = [\"domestic\", \"wild\", \"captive\"]\n",
    "pop_colours = [\"#FF0000\", \"#FFA500\", \"#0000FF\"]\n",
    "\n",
    "# Simulated data pca\n",
    "coords, model = allel.pca(genotypes, n_components=10, scaler='patterson')\n",
    "sim_df = pd.DataFrame({\"pc1\": coords[:, 0], \"pc2\": coords[:, 1],\n",
    "                       \"population\": sample_population, \"simulated_or_observed\": \"simulated\"})\n",
    "\n",
    "# Real data pca\n",
    "real_genotypes = np.loadtxt(\"../data/snps.012\", delimiter=\" \", skiprows=1)\n",
    "real_genotypes = real_genotypes[:,1:].transpose()  # Get rid of index and convert individuals to columns\n",
    "coords, model = allel.pca(real_genotypes, n_components=2, scaler='patterson')\n",
    "real_df = pd.DataFrame({\"pc1\": coords[:, 0], \"pc2\": coords[:, 1],\n",
    "                   \"population\": sample_population, \"simulated_or_observed\": \"observed\"})\n",
    "\n",
    "# Combined data\n",
    "combined_df = sim_df.append(real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid', font_scale=1.3)\n",
    "\n",
    "g = sns.relplot(x=\"pc1\", y=\"pc2\",\n",
    "                row=\"simulated_or_observed\", hue=\"population\",\n",
    "                kind=\"scatter\", data=combined_df,\n",
    "                facet_kws=dict(sharex=False, sharey=False),\n",
    "                aspect=1.4)\n",
    "\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Simulated\")\n",
    "axes[1].set_title(\"Observed\")\n",
    "\n",
    "#g.savefig(\"../plots/simulated_vs_observed_pca.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv(\"../output/summary_stats.csv\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_sum_stats = scaler.fit_transform(stats)\n",
    "scaler.inverse_transform(scaled_sum_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
