{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Script plots a PCA for the observed data, alongside a PCA using simulated data, utilising the medians of the priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sim.model\n",
    "sim.model.write_from_command_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary statistics calculated are:\n",
      "dict_keys(['random_seed', 'domestic_diversity', 'wild_diversity', 'captive_diversity', 'domestic_segregating_sites', 'wild_segregating_sites', 'captive_segregating_sites', 'domestic_tajimas_d', 'wild_tajimas_d', 'captive_tajimas_d', 'dom_wild_f2', 'dom_cap_f2', 'wild_cap_f2', 'dom_wild_divergence', 'dom_cap_divergence', 'wild_cap_divergence', 'domestic_f3', 'wild_f3', 'captive_f3', 'domestic_y3', 'wild_y3', 'captive_y3', 'dom_wild_fst', 'dom_cap_fst', 'wild_cap_fst', 'all_pops_diversity', 'all_pops_segregating_sites', 'all_pops_tajimas_d', 'domestic_afs_mean_1_2', 'domestic_afs_mean_3_3', 'domestic_afs_mean_4_4', 'domestic_afs_mean_5_5', 'wild_afs_mean_1_8', 'wild_afs_mean_9_16', 'wild_afs_mean_17_23', 'wild_afs_mean_24_30', 'captive_afs_mean_1_3', 'captive_afs_mean_4_6', 'captive_afs_mean_7_8', 'captive_afs_mean_9_10', 'all_pops_afs_mean_1_12', 'all_pops_afs_mean_13_23', 'all_pops_afs_mean_24_34', 'all_pops_afs_mean_35_45', 'all_pops_r2_median_0_1Mb', 'all_pops_r2_median_1_2Mb', 'all_pops_r2_median_2_4MB', 'captive_r2_median_0_1Mb', 'captive_r2_median_1_2Mb', 'captive_r2_median_2_4MB', 'domestic_r2_median_0_1Mb', 'domestic_r2_median_1_2Mb', 'domestic_r2_median_2_4MB', 'wild_r2_median_0_1Mb', 'wild_r2_median_1_2Mb', 'wild_r2_median_2_4MB', 'all_pops_r2_iqr_0_1Mb', 'all_pops_r2_iqr_1_2Mb', 'all_pops_r2_iqr_2_4MB', 'captive_r2_iqr_0_1Mb', 'captive_r2_iqr_1_2Mb', 'captive_r2_iqr_2_4MB', 'domestic_r2_iqr_0_1Mb', 'domestic_r2_iqr_1_2Mb', 'domestic_r2_iqr_2_4MB', 'wild_r2_iqr_0_1Mb', 'wild_r2_iqr_1_2Mb', 'wild_r2_iqr_2_4MB', 'captive_roh_length_median', 'domestic_roh_length_median', 'wild_roh_length_median', 'all_pops_roh_length_median', 'captive_roh_length_iqr', 'domestic_roh_length_iqr', 'wild_roh_length_iqr', 'all_pops_roh_length_iqr', 'domestic_roh_cov_median', 'domestic_roh_cov_iqr', 'wild_roh_cov_median', 'wild_roh_cov_iqr', 'captive_roh_cov_median', 'captive_roh_cov_iqr', 'all_pops_roh_cov_median', 'all_pops_roh_cov_iqr', 'captive_pc1_iqr', 'captive_pc2_iqr', 'domestic_pc1_iqr', 'domestic_pc2_iqr', 'wild_pc1_iqr', 'wild_pc2_iqr', 'all_pops_pc1_iqr', 'all_pops_pc2_iqr', 'pc1_pairwise_medians_dom_wild', 'pc2_pairwise_medians_dom_wild', 'pc1_pairwise_medians_dom_cap', 'pc2_pairwise_medians_dom_cap', 'pc1_pairwise_medians_wild_cap', 'pc2_pairwise_medians_wild_cap'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3.096444444444438e-05,\n",
       " 0.00045040870056495513,\n",
       " 0.0012840852631577446,\n",
       " 8.5e-05,\n",
       " 0.0032978,\n",
       " 0.003332,\n",
       " 0.15303448748133616,\n",
       " -1.3046733475812409,\n",
       " 1.541401541918025,\n",
       " 2.492942749529104e-05,\n",
       " 0.0002529651461988069,\n",
       " 0.0001127900181385575,\n",
       " 0.00026561600000002313,\n",
       " 0.0009104899999999526,\n",
       " 0.000980037000000101,\n",
       " 8.255227777778065e-05,\n",
       " -5.762285028248638e-05,\n",
       " 0.0001704128684210633,\n",
       " 9.803449999999956e-05,\n",
       " 0.00016758150000001427,\n",
       " 0.0008124555000000803,\n",
       " 0.04923820033541482,\n",
       " 0.16132828434988467,\n",
       " 0.06105721656563934,\n",
       " 0.0006392272159799937,\n",
       " 0.0034134,\n",
       " -0.1734786449358044,\n",
       " 128.5,\n",
       " 54.0,\n",
       " 86.0,\n",
       " 28.0,\n",
       " 1626.125,\n",
       " 414.125,\n",
       " 15.0,\n",
       " 8.857142857142858,\n",
       " 1659.6666666666667,\n",
       " 2251.3333333333335,\n",
       " 752.0,\n",
       " 1711.5,\n",
       " 1111.1666666666667,\n",
       " 324.27272727272725,\n",
       " 7.636363636363637,\n",
       " 7.454545454545454,\n",
       " 0.9999999999999996,\n",
       " 0.6974789915966385,\n",
       " 0.38235294117647045,\n",
       " 1.0,\n",
       " 0.7058823529411764,\n",
       " 0.26470588235294124,\n",
       " 0.07407407407407407,\n",
       " 0.062499999999999986,\n",
       " 0.06250000000000006,\n",
       " 1.0,\n",
       " 0.6551724137931034,\n",
       " 0.4827586206896549,\n",
       " 0.4137931034482757,\n",
       " 0.11127209504491486,\n",
       " 0.39148073022312385,\n",
       " 0.2941176470588236,\n",
       " 0.17647058823529393,\n",
       " 0.19607843137254924,\n",
       " 0.2222222222222222,\n",
       " 0.09876543209876545,\n",
       " 0.1388888888888889,\n",
       " 0.0,\n",
       " 1.1102230246251565e-16,\n",
       " 0.4597701149425286,\n",
       " 3733499.0,\n",
       " 4999999.0,\n",
       " 4999999.0,\n",
       " 4999999.0,\n",
       " 2534750.0,\n",
       " 0.0,\n",
       " 1072000.0,\n",
       " 1072000.0,\n",
       " 0.9999998,\n",
       " 0.0,\n",
       " 0.9999998,\n",
       " 0.19005000000000005,\n",
       " 0.7768997,\n",
       " 0.37965000000000004,\n",
       " 0.9999998,\n",
       " 0.21440000000000003,\n",
       " 24.932920455932617,\n",
       " 16.68375015258789,\n",
       " 0.5417995452880859,\n",
       " 2.9971206188201904,\n",
       " 4.160520076751709,\n",
       " 6.271690845489502,\n",
       " 5.997621059417725,\n",
       " 8.980282306671143,\n",
       " 0.34304237365722656,\n",
       " 2.7877681255340576,\n",
       " 12.36144733428955,\n",
       " 2.36918568611145,\n",
       " 12.018404960632324,\n",
       " 0.4185824692249298]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sim.model\n",
    "sim.model.run_sim([1,100,100,100,40,0.1,20,0.1,400, 400, 30000, 0.1, 5000, 3000, 20000, 3000, 20000, int(5e6), 1.8e-8, 6e-8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check add mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime\n",
    "import tskit\n",
    "tree_seq = msprime.simulate(sample_size=50, Ne=1000, length=10e3, mutation_rate=0, random_seed=20, recombination_rate=6e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "ss.uniform(0,1).rvs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_seq = msprime.mutate(tree_seq, rate=1e-2, keep=True, end_time=1, start_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in tree_seq.sites():\n",
    "     for mutation in site.mutations:\n",
    "            assert mutation.node in tree_seq.get_samples()\n",
    "\n",
    "print(\"{} mutations added above sample nodes\".format(tree_seq.num_mutations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in tree_seq.sites():\n",
    "     for mutation in site.mutations:\n",
    "        print(\"Mutation @ position {:.2f} over node {}\".format(\n",
    "            site.position, mutation.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = tree_seq.dump_tables().mutations\n",
    "print(mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_seq = msprime.mutate(tree_seq, rate=1e-4, keep=True, end_time=1, start_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = tree_seq.dump_tables().mutations\n",
    "print(mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_table = tree_seq.dump_tables().mutations\n",
    "print(mutation_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "All imports occur here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sim.model import SeqFeatures, WildcatSimulation\n",
    "from sim import sum_stats as ss\n",
    "import time\n",
    "import tskit\n",
    "import allel\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose parameters\n",
    "Choose some parameters so it runs relatively quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features = SeqFeatures(length=int(20e6), recombination_rate=1.8e-8, mutation_rate=6e-8)\n",
    "\n",
    "slim_parameters = {\n",
    "    'pop_size_domestic_1': 2000,  # Population sizes are diploid.\n",
    "    'pop_size_wild_1': 2000,\n",
    "    'pop_size_captive': 70,\n",
    "    'mig_rate_captive': 0.005,  # Migration from wild -> captive\n",
    "    'mig_length_wild': 34,\n",
    "    'mig_rate_wild': 0.008,  # Rate of migration from domestic -> wildcats\n",
    "    'captive_time': 28,  # Time captive population established in SLiM\n",
    "    }\n",
    "\n",
    "recapitate_parameters = {\n",
    "        'pop_size_domestic_2': 4000,\n",
    "        'pop_size_wild_2': 4000,\n",
    "        'div_time': 40000,\n",
    "        'mig_rate_post_split': 0.005,\n",
    "        'mig_length_post_split': 5000,\n",
    "        'bottleneck_time_wild': 3000,\n",
    "        'bottleneck_strength_wild': 20000,\n",
    "        'bottleneck_time_domestic': 3000,\n",
    "        'bottleneck_strength_domestic': 20000,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Run model\n",
    "sim = WildcatSimulation(seq_features=seq_features, random_seed=40)\n",
    "command = sim.slim_command(**slim_parameters)\n",
    "decap_trees = sim.run_slim(command)\n",
    "demographic_events = sim.demographic_model(**recapitate_parameters)\n",
    "tree_seq = sim.recapitate(decap_trees, demographic_events)\n",
    "\n",
    "# Print out useful bits and bobs\n",
    "print(\"Simulation finished in {:.2f} s\".format(time.time()-start_time))\n",
    "print(\"Command ran: {}\".format(command))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [5, 30, 10])  # Match number of samples to the WGS data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree_seq = tskit.load(\"tree_seq.trees\")\n",
    "#genotypes = tree_seq.genotype_matrix()\n",
    "#pop_list = 5*[\"domestic\"] + 30*[\"wild\"] + 10*[\"captive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes = ss.genotypes(tree_seq)\n",
    "pos = ss.positions(tree_seq)\n",
    "pop_list = ss.pop_list(tree_seq)\n",
    "samples = ss.sampled_nodes(tree_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tsinfer ancestral state irrelevant toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(np.array(genotypes), \"../output/test_genotypes.joblib\")\n",
    "joblib.dump(pos, \"../output/test_pos.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"AB\": [1,2,3], \"AC\": [5,4,5], \"CC\": [5,7,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in list(df) if \"A\" in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tsinfer ancestral state irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.loadtxt(\"../data/e3.012.pos\", delimiter=\"\\t\", usecols=1)\n",
    "genotypes = np.loadtxt(\"../data/e3.012\", delimiter=\"\\t\", usecols=range(1, len(positions)+1))\n",
    "genotypes = genotypes.T\n",
    "assert len(positions) == genotypes.shape[0]\n",
    "\n",
    "# For now just assume that missings are ancestral\n",
    "genotypes[genotypes == -1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cam read in with scikit allel but genotypes looks dodge\n",
    "callset = allel.read_vcf(\"../data/e3.vcf\")\n",
    "pos = callset[\"variants/POS\"]\n",
    "genotypes = allel.GenotypeArray(callset[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset[\"samples\"][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline(genotypes, pos, pop_list):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes, pop_list)\n",
    "    return pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = pd.read_csv(\"../data/e3_sample_info.csv\", usecols=[\"NAME\", \"SOURCE\"])\n",
    "\n",
    "# Ensure that individuals are in same order (after 012 conversion)\n",
    "assert np.all(sample_info[\"NAME\"] == np.loadtxt(\"../data/e3.012.indv\", dtype=str))\n",
    "\n",
    "pca_pipeline(genotypes, pos, sample_info[\"SOURCE\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsinfer\n",
    "\n",
    "with tsinfer.SampleData(sequence_length=6) as sample_data:\n",
    "    sample_data.add_site(0, [0, 1, 0, 0, 0], [\"A\", \"T\"])\n",
    "    sample_data.add_site(1, [0, 0, 0, 1, 1], [\"G\", \"C\"])\n",
    "    sample_data.add_site(2, [0, 1, 1, 0, 0], [\"C\", \"A\"])\n",
    "    sample_data.add_site(3, [0, 1, 1, 0, 0], [\"G\", \"C\"])\n",
    "    sample_data.add_site(4, [0, 0, 0, 1, 1], [\"A\", \"C\"])\n",
    "    sample_data.add_site(5, [0, 1, 2, 0, 0], [\"T\", \"G\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline(genotypes, pos, pop_list):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes, pop_list)\n",
    "    return pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_functions = [\n",
    "    ss.tskit_stats(tree_seq, samples),\n",
    "    ss.afs_stats(tree_seq, samples),\n",
    "    ss.r2_stats(tree_seq, samples, [0, 1e6, 2e6, 4e6], labels=[\"0_1Mb\", \"1_2Mb\", \"2_4MB\"]),\n",
    "    ss.roh_stats(genotypes, pos, pop_list, seq_features.length),\n",
    "    pca_pipeline(genotypes, pos, pop_list),\n",
    "]\n",
    "\n",
    "stats_dict = {\"random_seed\": sim.random_seed}  # Random seed acts as ID\n",
    "\n",
    "for func in summary_functions:\n",
    "    stat = func\n",
    "    stats_dict = {**stats_dict, **stat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caluculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the WGS data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "\n",
    "# Calculate summary statistics\n",
    "def pca_pipeline(genotypes, pos):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes)\n",
    "    return pca_stats\n",
    "\n",
    "genotypes = ss.sampled_genotypes(tree_seq)  # scikit-allel format\n",
    "pos = ss.positions(tree_seq)\n",
    "\n",
    "# Using a list to call function in for loop so we can use try/except (in case any functions fail)\n",
    "summary_functions = [\n",
    "    sum_stats.tskit_stats(),\n",
    "    sum_stats.afs_stats(),\n",
    "    sum_stats.r2_stats(),\n",
    "    sum_stats.roh_stats(genotypes, pos),\n",
    "    pca_pipeline(genotypes, pos),\n",
    "]\n",
    "\n",
    "stats_dict = {\"random_seed\": sim.random_seed}  # Random seed acts as ID\n",
    "\n",
    "for func in summary_functions:\n",
    "    stat = func\n",
    "    stats_dict = {**stats_dict, **stat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_stats = {'domestic_roh_cov_median': 0.9996666, 'domestic_roh_cov_iqr': 0.00022224444444440827, 'wild_roh_cov_median': 0.6211887222222223, 'wild_roh_cov_iqr': 0.19288330555555555, 'captive_roh_cov_median': 0.8555888222222222, 'captive_roh_cov_iqr': 0.10507222222222223}\n",
    "coverage_stats[\"all_pops_roh_cov_median\"] = np.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(prior_df[[\"mig_rate_wild\", \"mig_rate_post_split\"]]<=1) & np.all(prior_df[[\"mig_rate_wild\", \"mig_rate_post_split\"]]>=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ROH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below seems fine but we should probably filter minor alleles. With this a single mutation breaks a ROH... I think that is ok? Presumably v. informative for PODs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the SNP data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "sum_stats = SummaryStatistics(tree_seq, sim)\n",
    "genotypes = sum_stats.sampled_genotypes()\n",
    "is_homo = genotypes[:,:,0] == genotypes[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roh_id = pd.DataFrame(np.cumsum(is_homo == False, axis=0))  # Increment ID with each heterozygote\n",
    "roh_id[\"position\"] = sim_tools.positions(tree_seq)\n",
    "df = roh_id.melt(id_vars=\"position\", var_name=\"individual\", value_name=\"roh_id\")\n",
    "df = df.groupby([\"individual\", \"roh_id\"])[\"position\"].max().reset_index()\n",
    "df[\"roh_length\"] = df.groupby('individual')['position'].diff(1)\n",
    "df = df.dropna()  # Drops first \"ROH\" (as no previous heterozygote)\n",
    "df = df.drop(columns = [\"position\", \"roh_id\"])\n",
    "# pd.DataFrame({\"population\": sum_stats.individual_pop_list, \"id\": range(0, len(sum_stats.individual_pop_list))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a sample and get the genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the SNP data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes = ss.genotypes(tree_seq)\n",
    "pos = ss.positions(tree_seq)\n",
    "pop_list = ss.pop_list(tree_seq)\n",
    "samples = ss.sampled_nodes(tree_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ld(gn, title):\n",
    "    m = allel.rogers_huff_r(gn) ** 2\n",
    "    ax = allel.plot_pairwise_ld(m)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ld(genotypes[:1000].to_n_alt(), 'Pairwise LD.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter singletons and SNPs in LD\n",
    "SNPs in LD can bias PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "genotypes, pos = ss.ld_prune(genotypes.to_n_alt(), pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ld(genotypes[:1000], 'Pairwise LD after pruning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_population = np.asarray([\"domestic\"]*4 + [\"wild\"]*45 + [\"captive\"]*46)\n",
    "populations = [\"domestic\", \"wild\", \"captive\"]\n",
    "pop_colours = [\"#FF0000\", \"#FFA500\", \"#0000FF\"]\n",
    "\n",
    "# Simulated data pca\n",
    "coords, model = allel.pca(genotypes, n_components=10, scaler='patterson')\n",
    "sim_df = pd.DataFrame({\"pc1\": coords[:, 0], \"pc2\": coords[:, 1],\n",
    "                       \"population\": sample_population, \"simulated_or_observed\": \"simulated\"})\n",
    "\n",
    "# Real data pca\n",
    "real_genotypes = np.loadtxt(\"../data/snps.012\", delimiter=\" \", skiprows=1)\n",
    "real_genotypes = real_genotypes[:,1:].transpose()  # Get rid of index and convert individuals to columns\n",
    "coords, model = allel.pca(real_genotypes, n_components=2, scaler='patterson')\n",
    "real_df = pd.DataFrame({\"pc1\": coords[:, 0], \"pc2\": coords[:, 1],\n",
    "                   \"population\": sample_population, \"simulated_or_observed\": \"observed\"})\n",
    "\n",
    "# Combined data\n",
    "combined_df = sim_df.append(real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid', font_scale=1.3)\n",
    "\n",
    "g = sns.relplot(x=\"pc1\", y=\"pc2\",\n",
    "                row=\"simulated_or_observed\", hue=\"population\",\n",
    "                kind=\"scatter\", data=combined_df,\n",
    "                facet_kws=dict(sharex=False, sharey=False),\n",
    "                aspect=1.4)\n",
    "\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Simulated\")\n",
    "axes[1].set_title(\"Observed\")\n",
    "\n",
    "#g.savefig(\"../plots/simulated_vs_observed_pca.png\", dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
