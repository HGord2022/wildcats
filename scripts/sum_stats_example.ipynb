{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Script plots a PCA for the observed data, alongside a PCA using simulated data, utilising the medians of the priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "All imports occur here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "demographic_events = joblib.load(\"demographic_events.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'population_parameters_change', 'time': 2768, 'growth_rate': None, 'initial_size': 11587, 'population': 0},\n",
       " {'type': 'instantaneous_bottleneck', 'time': 2768, 'population': 0, 'strength': 35899},\n",
       " {'type': 'population_parameters_change', 'time': 3149, 'growth_rate': None, 'initial_size': 8294, 'population': 1},\n",
       " {'type': 'instantaneous_bottleneck', 'time': 3149, 'population': 1, 'strength': 613},\n",
       " {'type': 'migration_rate_change', 'time': 42763, 'rate': -0.13202131690920388, 'matrix_index': (0, 1)},\n",
       " {'type': 'migration_rate_change', 'time': 42763, 'rate': -0.13202131690920388, 'matrix_index': (1, 0)},\n",
       " {'type': 'mass_migration', 'time': 44052, 'source': 0, 'dest': 1, 'proportion': 1}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sim.model import SeqFeatures, WildcatSimulation\n",
    "from sim import sum_stats as ss\n",
    "import time\n",
    "import tskit\n",
    "import allel\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "def normal_sim(a, b):\n",
    "    return np.sort(np.random.normal(a, b, 1000))\n",
    "\n",
    "with pm.Model() as example:\n",
    "    a = pm.Normal('a', mu=0, sd=5)\n",
    "    b = pm.HalfNormal('b', sd=1)\n",
    "    s = pm.Simulator('s', normal_sim, observed=np.sort(data))\n",
    "    trace_example = pm.smc.SMC(kernel=\"ABC\", epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only convert xarray dataset, dict, netcdf filename, numpy array, pystan fit, pymc3 trace, emcee fit, pyro mcmc fit, numpyro mcmc fit, cmdstan fit csv filename, cmdstanpy fit to InferenceData, not SMC",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-335ecdd8f1c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marviz\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0maz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_example\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\wildcats_summer_env\\lib\\site-packages\\arviz\\plots\\traceplot.py\u001b[0m in \u001b[0;36mplot_trace\u001b[1;34m(data, var_names, coords, divergences, figsize, rug, lines, compact, combined, legend, plot_kwargs, fill_kwargs, rug_kwargs, hist_kwargs, trace_kwargs, backend, backend_kwargs, show)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mdivergence_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_coords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_to_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"posterior\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[0mvar_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_var_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\wildcats_summer_env\\lib\\site-packages\\arviz\\data\\converters.py\u001b[0m in \u001b[0;36mconvert_to_dataset\u001b[1;34m(obj, group, coords, dims)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[0mxarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \"\"\"\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[0minference_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_inference_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minference_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\wildcats_summer_env\\lib\\site-packages\\arviz\\data\\converters.py\u001b[0m in \u001b[0;36mconvert_to_inference_data\u001b[1;34m(obj, group, coords, dims, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m         raise ValueError(\n\u001b[0;32m    125\u001b[0m             \"Can only convert {} to InferenceData, not {}\".format(\n\u001b[1;32m--> 126\u001b[1;33m                 \u001b[1;34m\", \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallowable_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             )\n\u001b[0;32m    128\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Can only convert xarray dataset, dict, netcdf filename, numpy array, pystan fit, pymc3 trace, emcee fit, pyro mcmc fit, numpyro mcmc fit, cmdstan fit csv filename, cmdstanpy fit to InferenceData, not SMC"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "az.plot_trace(trace_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose parameters\n",
    "Choose some parameters so it runs relatively quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features = SeqFeatures(length=int(20e6), recombination_rate=1.8e-8, mutation_rate=6e-8)\n",
    "\n",
    "slim_parameters = {\n",
    "    'pop_size_domestic_1': 2000,  # Population sizes are diploid.\n",
    "    'pop_size_wild_1': 2000,\n",
    "    'pop_size_captive': 70,\n",
    "    'mig_rate_captive': 0.005,  # Migration from wild -> captive\n",
    "    'mig_length_wild': 34,\n",
    "    'mig_rate_wild': 0.008,  # Rate of migration from domestic -> wildcats\n",
    "    'captive_time': 28,  # Time captive population established in SLiM\n",
    "    }\n",
    "\n",
    "recapitate_parameters = {\n",
    "        'pop_size_domestic_2': 4000,\n",
    "        'pop_size_wild_2': 4000,\n",
    "        'div_time': 40000,\n",
    "        'mig_rate_post_split': 0.005,\n",
    "        'mig_length_post_split': 5000,\n",
    "        'bottleneck_time_wild': 3000,\n",
    "        'bottleneck_strength_wild': 20000,\n",
    "        'bottleneck_time_domestic': 3000,\n",
    "        'bottleneck_strength_domestic': 20000,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run_slim function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan is to do it as dictionary, to tempfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = WildcatSimulation(seq_features=seq_features, random_seed=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = sim.slim_command(slim_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyslim.slim_tree_sequence.SlimTreeSequence at 0x26500c47f08>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.run_slim(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'slim -d pop_size_domestic_1=2000 -d pop_size_wild_1=2000 -d pop_size_captive=70 -d length=20000000 -d recombination_rate=1.8e-08 -d mig_rate_captive=0.005 -d mig_length_wild=34 -d mig_rate_wild=0.008 -d captive_time=28 -d decap_trees_filename=\\'\"../output/decap_40.trees\"\\' -s 40 ./slim_model.slim'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.slim_command_old(**slim_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Run model\n",
    "sim = WildcatSimulation(seq_features=seq_features, random_seed=40)\n",
    "command = sim.slim_command(**slim_parameters)\n",
    "decap_trees = sim.run_slim(command)\n",
    "demographic_events = sim.demographic_model(**recapitate_parameters)\n",
    "tree_seq = sim.recapitate(decap_trees, demographic_events)\n",
    "\n",
    "# Print out useful bits and bobs\n",
    "print(\"Simulation finished in {:.2f} s\".format(time.time()-start_time))\n",
    "print(\"Command ran: {}\".format(command))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [5, 30, 10])  # Match number of samples to the WGS data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree_seq = tskit.load(\"tree_seq.trees\")\n",
    "#genotypes = tree_seq.genotype_matrix()\n",
    "#pop_list = 5*[\"domestic\"] + 30*[\"wild\"] + 10*[\"captive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes = ss.genotypes(tree_seq)\n",
    "pos = ss.positions(tree_seq)\n",
    "pop_list = ss.pop_list(tree_seq)\n",
    "samples = ss.sampled_nodes(tree_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tsinfer ancestral state irrelevant toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(np.array(genotypes), \"../output/test_genotypes.joblib\")\n",
    "joblib.dump(pos, \"../output/test_pos.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"AB\": [1,2,3], \"AC\": [5,4,5], \"CC\": [5,7,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in list(df) if \"A\" in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tsinfer ancestral state irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.loadtxt(\"../data/e3.012.pos\", delimiter=\"\\t\", usecols=1)\n",
    "genotypes = np.loadtxt(\"../data/e3.012\", delimiter=\"\\t\", usecols=range(1, len(positions)+1))\n",
    "genotypes = genotypes.T\n",
    "assert len(positions) == genotypes.shape[0]\n",
    "\n",
    "# For now just assume that missings are ancestral\n",
    "genotypes[genotypes == -1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cam read in with scikit allel but genotypes looks dodge\n",
    "callset = allel.read_vcf(\"../data/e3.vcf\")\n",
    "pos = callset[\"variants/POS\"]\n",
    "genotypes = allel.GenotypeArray(callset[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset[\"samples\"][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline(genotypes, pos, pop_list):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes, pop_list)\n",
    "    return pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = pd.read_csv(\"../data/e3_sample_info.csv\", usecols=[\"NAME\", \"SOURCE\"])\n",
    "\n",
    "# Ensure that individuals are in same order (after 012 conversion)\n",
    "assert np.all(sample_info[\"NAME\"] == np.loadtxt(\"../data/e3.012.indv\", dtype=str))\n",
    "\n",
    "pca_pipeline(genotypes, pos, sample_info[\"SOURCE\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsinfer\n",
    "\n",
    "with tsinfer.SampleData(sequence_length=6) as sample_data:\n",
    "    sample_data.add_site(0, [0, 1, 0, 0, 0], [\"A\", \"T\"])\n",
    "    sample_data.add_site(1, [0, 0, 0, 1, 1], [\"G\", \"C\"])\n",
    "    sample_data.add_site(2, [0, 1, 1, 0, 0], [\"C\", \"A\"])\n",
    "    sample_data.add_site(3, [0, 1, 1, 0, 0], [\"G\", \"C\"])\n",
    "    sample_data.add_site(4, [0, 0, 0, 1, 1], [\"A\", \"C\"])\n",
    "    sample_data.add_site(5, [0, 1, 2, 0, 0], [\"T\", \"G\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline(genotypes, pos, pop_list):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes, pop_list)\n",
    "    return pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_functions = [\n",
    "    ss.tskit_stats(tree_seq, samples),\n",
    "    ss.afs_stats(tree_seq, samples),\n",
    "    ss.r2_stats(tree_seq, samples, [0, 1e6, 2e6, 4e6], labels=[\"0_1Mb\", \"1_2Mb\", \"2_4MB\"]),\n",
    "    ss.roh_stats(genotypes, pos, pop_list, seq_features.length),\n",
    "    pca_pipeline(genotypes, pos, pop_list),\n",
    "]\n",
    "\n",
    "stats_dict = {\"random_seed\": sim.random_seed}  # Random seed acts as ID\n",
    "\n",
    "for func in summary_functions:\n",
    "    stat = func\n",
    "    stats_dict = {**stats_dict, **stat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caluculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the WGS data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "\n",
    "# Calculate summary statistics\n",
    "def pca_pipeline(genotypes, pos):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes)\n",
    "    return pca_stats\n",
    "\n",
    "genotypes = ss.sampled_genotypes(tree_seq)  # scikit-allel format\n",
    "pos = ss.positions(tree_seq)\n",
    "\n",
    "# Using a list to call function in for loop so we can use try/except (in case any functions fail)\n",
    "summary_functions = [\n",
    "    sum_stats.tskit_stats(),\n",
    "    sum_stats.afs_stats(),\n",
    "    sum_stats.r2_stats(),\n",
    "    sum_stats.roh_stats(genotypes, pos),\n",
    "    pca_pipeline(genotypes, pos),\n",
    "]\n",
    "\n",
    "stats_dict = {\"random_seed\": sim.random_seed}  # Random seed acts as ID\n",
    "\n",
    "for func in summary_functions:\n",
    "    stat = func\n",
    "    stats_dict = {**stats_dict, **stat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_stats = {'domestic_roh_cov_median': 0.9996666, 'domestic_roh_cov_iqr': 0.00022224444444440827, 'wild_roh_cov_median': 0.6211887222222223, 'wild_roh_cov_iqr': 0.19288330555555555, 'captive_roh_cov_median': 0.8555888222222222, 'captive_roh_cov_iqr': 0.10507222222222223}\n",
    "coverage_stats[\"all_pops_roh_cov_median\"] = np.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(prior_df[[\"mig_rate_wild\", \"mig_rate_post_split\"]]<=1) & np.all(prior_df[[\"mig_rate_wild\", \"mig_rate_post_split\"]]>=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ROH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below seems fine but we should probably filter minor alleles. With this a single mutation breaks a ROH... I think that is ok? Presumably v. informative for PODs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the SNP data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "sum_stats = SummaryStatistics(tree_seq, sim)\n",
    "genotypes = sum_stats.sampled_genotypes()\n",
    "is_homo = genotypes[:,:,0] == genotypes[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roh_id = pd.DataFrame(np.cumsum(is_homo == False, axis=0))  # Increment ID with each heterozygote\n",
    "roh_id[\"position\"] = sim_tools.positions(tree_seq)\n",
    "df = roh_id.melt(id_vars=\"position\", var_name=\"individual\", value_name=\"roh_id\")\n",
    "df = df.groupby([\"individual\", \"roh_id\"])[\"position\"].max().reset_index()\n",
    "df[\"roh_length\"] = df.groupby('individual')['position'].diff(1)\n",
    "df = df.dropna()  # Drops first \"ROH\" (as no previous heterozygote)\n",
    "df = df.drop(columns = [\"position\", \"roh_id\"])\n",
    "# pd.DataFrame({\"population\": sum_stats.individual_pop_list, \"id\": range(0, len(sum_stats.individual_pop_list))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a sample and get the genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the SNP data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes = ss.genotypes(tree_seq)\n",
    "pos = ss.positions(tree_seq)\n",
    "pop_list = ss.pop_list(tree_seq)\n",
    "samples = ss.sampled_nodes(tree_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ld(gn, title):\n",
    "    m = allel.rogers_huff_r(gn) ** 2\n",
    "    ax = allel.plot_pairwise_ld(m)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ld(genotypes[:1000].to_n_alt(), 'Pairwise LD.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter singletons and SNPs in LD\n",
    "SNPs in LD can bias PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "genotypes, pos = ss.ld_prune(genotypes.to_n_alt(), pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ld(genotypes[:1000], 'Pairwise LD after pruning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_population = np.asarray([\"domestic\"]*4 + [\"wild\"]*45 + [\"captive\"]*46)\n",
    "populations = [\"domestic\", \"wild\", \"captive\"]\n",
    "pop_colours = [\"#FF0000\", \"#FFA500\", \"#0000FF\"]\n",
    "\n",
    "# Simulated data pca\n",
    "coords, model = allel.pca(genotypes, n_components=10, scaler='patterson')\n",
    "sim_df = pd.DataFrame({\"pc1\": coords[:, 0], \"pc2\": coords[:, 1],\n",
    "                       \"population\": sample_population, \"simulated_or_observed\": \"simulated\"})\n",
    "\n",
    "# Real data pca\n",
    "real_genotypes = np.loadtxt(\"../data/snps.012\", delimiter=\" \", skiprows=1)\n",
    "real_genotypes = real_genotypes[:,1:].transpose()  # Get rid of index and convert individuals to columns\n",
    "coords, model = allel.pca(real_genotypes, n_components=2, scaler='patterson')\n",
    "real_df = pd.DataFrame({\"pc1\": coords[:, 0], \"pc2\": coords[:, 1],\n",
    "                   \"population\": sample_population, \"simulated_or_observed\": \"observed\"})\n",
    "\n",
    "# Combined data\n",
    "combined_df = sim_df.append(real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid', font_scale=1.3)\n",
    "\n",
    "g = sns.relplot(x=\"pc1\", y=\"pc2\",\n",
    "                row=\"simulated_or_observed\", hue=\"population\",\n",
    "                kind=\"scatter\", data=combined_df,\n",
    "                facet_kws=dict(sharex=False, sharey=False),\n",
    "                aspect=1.4)\n",
    "\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Simulated\")\n",
    "axes[1].set_title(\"Observed\")\n",
    "\n",
    "#g.savefig(\"../plots/simulated_vs_observed_pca.png\", dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
