{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Notebook contains regression projection for summary statistc dimensionality reduction prior to approximate Bayesian computation (see https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2011.01010.x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "All imporst occur here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in summary statistics and parameters (priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_stats = pd.read_csv(\"../output/summary_stats.csv\", index_col=False)\n",
    "prior = pd.read_feather(\"../output/prior.feather\")\n",
    "assert np.all(sum_stats[\"random_seed\"] == prior[\"random_seed\"]) # Make sure everthing is aligned\n",
    "\n",
    "seeds = sum_stats.pop(\"random_seed\")\n",
    "prior = prior.drop(columns=\"random_seed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into test set and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set == pseudo-observed datasets. Leaving 2000 out as PODs.\n",
    "train_prior = prior.iloc[:-2000]\n",
    "train_sum_stats = sum_stats.iloc[:-2000]\n",
    "\n",
    "test_prior = prior.iloc[-2000:]\n",
    "test_sum_stats = sum_stats.iloc[-2000:]\n",
    "\n",
    "train_prior.to_csv(\"../output/train_prior.csv\", index=False)\n",
    "train_sum_stats.to_csv(\"../output/train_sum_stats.csv\", index=False)\n",
    "test_prior.to_csv(\"../output/test_prior.csv\", index=False)\n",
    "test_sum_stats.to_csv(\"../output/test_sum_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-observed datasets based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up linear regression, lasso regression and random forest regression models\n",
    "model_dict = {\"linear_regression\": LinearRegression(),\n",
    "              \"lasso_regression\": pipeline.make_pipeline(StandardScaler(), Lasso(max_iter=50000, alpha=0.5)),\n",
    "              \"random_forest\": RandomForestRegressor(n_estimators=150, n_jobs=-1)\n",
    "             }\n",
    "\n",
    "# Set up objects to store results\n",
    "parameters = list(prior)\n",
    "train_sum_stats_pred = dict(zip(model_dict.keys(), [{} for i in range(0, len(model_dict.keys()))]))\n",
    "test_sum_stats_pred = dict(zip(model_dict.keys(), [{} for i in range(0, len(model_dict.keys()))]))\n",
    "rmse_results = pd.DataFrame(columns = [model + \"_RMSE\" for model in model_dict.keys()], index=list(prior))\n",
    "\n",
    "linear_regression_coefficients = pd.DataFrame(columns=parameters, index=list(sum_stats))\n",
    "lasso_regression_coefficients = pd.DataFrame(columns=parameters, index=list(sum_stats))\n",
    "random_forest_importances = pd.DataFrame(columns=parameters, index=list(sum_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Loop through parameters, fit models\n",
    "for param in parameters:  # Loop through wildcat model parameters\n",
    "    print(\"Parameter: {}\".format(param))\n",
    "    y = prior[[param]].values.ravel()\n",
    "    y_train = y[:-2000]\n",
    "    y_test = y[-2000:]\n",
    "    for name, model in model_dict.items():\n",
    "        \n",
    "        # Train the model on the training set\n",
    "        print(\" - Training {} ...\".format(name))\n",
    "        start_time = time()\n",
    "        estimator = model.fit(train_sum_stats, train_prior[param])\n",
    "        print(\" - Training completed and moddel saved in {:.2f} s\".format(time() - start_time))\n",
    "        \n",
    "        # Predict on the train and test set\n",
    "        train_pred = estimator.predict(train_sum_stats)\n",
    "        train_sum_stats_pred[name] = {**train_sum_stats_pred[name], param: train_pred}\n",
    "        \n",
    "        test_pred = estimator.predict(test_sum_stats)\n",
    "        test_sum_stats_pred[name] = {**test_sum_stats_pred[name], param: test_pred}\n",
    "        \n",
    "        # Calculate RMSE using test set:\n",
    "        rmse_results.loc[param, name + \"_RMSE\"] = mean_squared_error(test_prior[param], test_pred, squared=False)\n",
    "        \n",
    "        # Record importances and coefficients\n",
    "        if name == \"linear_regression\":\n",
    "            linear_regression_coefficients[param] = estimator.coef_\n",
    "        elif name == \"lasso_regression\":\n",
    "            lasso_regression_coefficients[param] = estimator[\"lasso\"].coef_\n",
    "        elif name == \"random_forest\":\n",
    "            random_forest_importances[param] = estimator.feature_importances_\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, results in train_sum_stats_pred.items():\n",
    "    df = pd.DataFrame(results)\n",
    "    filename = \"../output/projection/{}_train_sum_stats_projection.csv\".format(model)\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "for model, results in test_sum_stats_pred.items():\n",
    "    df = pd.DataFrame(results)\n",
    "    filename = \"../output/projection/{}_test_sum_stats_projection.csv\".format(model)\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "rmse_results.to_csv(\"../output/projection/rmse_results.csv\", index_label = \"parameter\")\n",
    "\n",
    "linear_regression_coefficients.to_csv(\"../output/projection/linear_regression_coefficients.csv\", index_label=\"summary_stats\")\n",
    "lasso_regression_coefficients.to_csv(\"../output/projection/lasso_regression_coefficients.csv\", index_label=\"summary_stats\")\n",
    "random_forest_importances.to_csv(\"../output/projection/random_forest_importances.csv\", index_label=\"summary_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot importances for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in parameters:\n",
    "    importances = random_forest_importances[param].sort_values(ascending=False)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    f, ax = plt.subplots(figsize=(10, 14))\n",
    "    sns.barplot(x=importances, y=importances.index, color = \"0.2\", orient=\"h\")\n",
    "    plt.xlabel(\"Importances for predicting {}\".format(param))\n",
    "    plt.ylabel(\"Summary statistic\".format(param))\n",
    "    plt.gcf().subplots_adjust(left=0.3)\n",
    "    plt.savefig(\"../plots/importances/importance_{}.png\".format(param))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of these results will be plotted in R (abc.R)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
